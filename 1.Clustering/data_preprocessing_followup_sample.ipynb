{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1患者组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\nfrom sklearn.experimental import enable_iterative_imputer\\nfrom sklearn.impute import IterativeImputer\\n\\n# Read the Excel file\\n\\ndf = pd.read_excel(\\'./rawdata(EF+deo).xlsx\\', sheet_name=\\'86名患者\\')\\n\\nprint(df.columns)\\n# Specify the behavior variables\\nbehavior_variables = [ \\'Stroop_incongruent_rt\\',\\n       \\'Stroop_interference effect_rt\\', \\'Nogo_acc\\',\\n       \\'Switch_cost\\', \\'RM-1,750_acc\\', \\'RM-750_acc\\', \\'DSBT_Span\\',\\n      ]\\n# Extract the behavior variables data from the DataFrame\\nbehavior_data = df[behavior_variables]\\n\\n# Check for missing values in the behavior variables before imputation\\nmissing_values_before = behavior_data.isna().sum()\\nprint(\"Missing values before imputation:\")\\nprint(missing_values_before)\\n\\n# Use IterativeImputer (MICE) for multiple imputation with adjusted parameters\\nimputer = IterativeImputer(random_state=42, \\n                           max_iter=10,  # Increase the maximum number of iterations \\n                           tol=1e-3,     # Adjust the tolerance for convergence\\n                           verbose=2)    # Print out progress during imputation\\nimputed_behavior_data = imputer.fit_transform(behavior_data)\\n\\n# Convert the imputed data back to a DataFrame\\nbehavior_df = pd.DataFrame(imputed_behavior_data, columns=behavior_variables)\\n\\n# Add the imputed behavior data to the original DataFrame\\nfor variable in behavior_variables:\\n    df[variable] = behavior_df[variable]\\n\\n# Check for missing values in the updated DataFrame\\nmissing_values_after = df[behavior_variables].isna().sum()\\nprint(\"Missing values after imputation:\")\\nprint(missing_values_after)\\n\\n# Save the updated DataFrame to a new Excel file  \\ndf.to_excel(\\'./table/预处理后的rawdata-86名患者.xlsx\\', index=False)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Read the Excel file\n",
    "\n",
    "df = pd.read_excel('./rawdata(EF+deo).xlsx', sheet_name='86名患者')\n",
    "\n",
    "print(df.columns)\n",
    "# Specify the behavior variables\n",
    "behavior_variables = [ 'Stroop_incongruent_rt',\n",
    "       'Stroop_interference effect_rt', 'Nogo_acc',\n",
    "       'Switch_cost', 'RM-1,750_acc', 'RM-750_acc', 'DSBT_Span',\n",
    "      ]\n",
    "# Extract the behavior variables data from the DataFrame\n",
    "behavior_data = df[behavior_variables]\n",
    "\n",
    "# Check for missing values in the behavior variables before imputation\n",
    "missing_values_before = behavior_data.isna().sum()\n",
    "print(\"Missing values before imputation:\")\n",
    "print(missing_values_before)\n",
    "\n",
    "# Use IterativeImputer (MICE) for multiple imputation with adjusted parameters\n",
    "imputer = IterativeImputer(random_state=42, \n",
    "                           max_iter=10,  # Increase the maximum number of iterations \n",
    "                           tol=1e-3,     # Adjust the tolerance for convergence\n",
    "                           verbose=2)    # Print out progress during imputation\n",
    "imputed_behavior_data = imputer.fit_transform(behavior_data)\n",
    "\n",
    "# Convert the imputed data back to a DataFrame\n",
    "behavior_df = pd.DataFrame(imputed_behavior_data, columns=behavior_variables)\n",
    "\n",
    "# Add the imputed behavior data to the original DataFrame\n",
    "for variable in behavior_variables:\n",
    "    df[variable] = behavior_df[variable]\n",
    "\n",
    "# Check for missing values in the updated DataFrame\n",
    "missing_values_after = df[behavior_variables].isna().sum()\n",
    "print(\"Missing values after imputation:\")\n",
    "print(missing_values_after)\n",
    "\n",
    "# Save the updated DataFrame to a new Excel file  \n",
    "df.to_excel('./table/预处理后的rawdata-86名患者.xlsx', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2对照组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before imputation:\n",
      "Stroop_incongruent_rt            0\n",
      "Stroop_interference effect_rt    1\n",
      "Nogo_acc                         0\n",
      "Switch_cost                      0\n",
      "RM-1,750_acc                     2\n",
      "RM-750_acc                       0\n",
      "DSBT_Span                        0\n",
      "dtype: int64\n",
      "[IterativeImputer] Completing matrix with shape (169, 7)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 0.00\n",
      "[IterativeImputer] Change: 0.2205961406144139, scaled tolerance: 1.2313110516934 \n",
      "[IterativeImputer] Early stopping criterion reached.\n",
      "Missing values after imputation:\n",
      "Stroop_incongruent_rt            0\n",
      "Stroop_interference effect_rt    0\n",
      "Nogo_acc                         0\n",
      "Switch_cost                      0\n",
      "RM-1,750_acc                     0\n",
      "RM-750_acc                       0\n",
      "DSBT_Span                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel('./rawdata(EF+deo).xlsx', sheet_name='167健康')\n",
    "\n",
    "# Specify the behavior variables\n",
    "behavior_variables =  [ 'Stroop_incongruent_rt',\n",
    "       'Stroop_interference effect_rt', 'Nogo_acc',\n",
    "       'Switch_cost', 'RM-1,750_acc', 'RM-750_acc', 'DSBT_Span',\n",
    "       ]\n",
    "\n",
    "# Extract the behavior variables data from the DataFrame\n",
    "behavior_data = df[behavior_variables]\n",
    "\n",
    "\n",
    "# Check for missing values in the behavior variables before imputation\n",
    "missing_values_before = behavior_data.isna().sum()\n",
    "print(\"Missing values before imputation:\")\n",
    "print(missing_values_before)\n",
    "\n",
    "# Use IterativeImputer (MICE) for multiple imputation with adjusted parameters\n",
    "imputer = IterativeImputer(random_state=42, \n",
    "                           max_iter=10,  # Increase the maximum number of iterations\n",
    "                           tol=1e-3,     # Adjust the tolerance for convergence\n",
    "                           verbose=2)    # Print out progress during imputation\n",
    "imputed_behavior_data = imputer.fit_transform(behavior_data)\n",
    "\n",
    "# Convert the imputed data back to a DataFrame\n",
    "behavior_df = pd.DataFrame(imputed_behavior_data, columns=behavior_variables)\n",
    "\n",
    "# Add the imputed behavior data to the original DataFrame\n",
    "for variable in behavior_variables:\n",
    "    df[variable] = behavior_df[variable]\n",
    "\n",
    "# Check for missing values in the updated DataFrame\n",
    "missing_values = df[behavior_variables].isna().sum()\n",
    "print(\"Missing values after imputation:\")\n",
    "print(missing_values)\n",
    "\n",
    "df.to_excel('./table/预处理后的rawdata-167健康.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Stroop_incongruent_rt  Stroop_interference effect_rt  Nogo_acc  \\\n",
      "0              -1.129613                       8.679037 -1.136804   \n",
      "1               0.086965                      18.911147 -2.173654   \n",
      "2               0.092872                      15.675690 -2.573757   \n",
      "3              -0.576370                      14.936274 -0.232888   \n",
      "4              -0.372341                      16.227554 -0.522282   \n",
      "\n",
      "   Switch_cost  RM-1,750_acc  RM-750_acc  DSBT_Span  \n",
      "0    -0.291857     -4.221235   -3.706490  -7.867031  \n",
      "1    -0.082916     -1.097726   -0.139313  -5.909032  \n",
      "2    -0.234644     -2.552458   -3.130552  -8.194945  \n",
      "3    -0.373952     -1.829976   -2.162388  -8.799739  \n",
      "4    -0.071791     -3.778377   -2.396202  -6.626771  \n",
      "校正并标准化完成，数据已保存到'./table/校正并标准化后的患者行为变量数据.xlsx'.\n",
      "                              Corrected and Standardized Patient\n",
      "Stroop_incongruent_rt                                -0.4 ± 0.91\n",
      "Stroop_interference effect_rt                      13.97 ± 11.09\n",
      "Nogo_acc                                            -1.26 ± 1.33\n",
      "Switch_cost                                         -0.15 ± 0.13\n",
      "RM-1,750_acc                                        -1.76 ± 1.34\n",
      "RM-750_acc                                           -1.7 ± 1.25\n",
      "DSBT_Span                                           -6.71 ± 1.04\n",
      "校正并标准化后的均值和标准差已保存到'./table/校正并标准化后的行为变量均值和标准差.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 读取Excel文件\n",
    "patients_df = pd.read_excel('./table/预处理后的rawdata-86名患者.xlsx')\n",
    "control_df = pd.read_excel('./table/预处理后的rawdata-167健康.xlsx')\n",
    "\n",
    "\n",
    "continuous_variables = ['Age', 'Education_years']\n",
    "categorical_variables = ['Gender']\n",
    "behavior_variables = ['Stroop_incongruent_rt', 'Stroop_interference effect_rt', 'Nogo_acc', 'Switch_cost', 'RM-1,750_acc', 'RM-750_acc', 'DSBT_Span']\n",
    "# 对反应时变量取倒数\n",
    "patients_df['Stroop_incongruent_rt'] = 1 / patients_df['Stroop_incongruent_rt']\n",
    "patients_df['Switch_cost'] = 1 / patients_df['Switch_cost']\n",
    "control_df['Stroop_incongruent_rt'] = 1 / control_df['Stroop_incongruent_rt']\n",
    "control_df['Switch_cost'] = 1 / control_df['Switch_cost']\n",
    "# One-hot encode categorical variables\n",
    "def one_hot_encode(df, categorical_vars):\n",
    "    for var in categorical_vars:\n",
    "        dummies = pd.get_dummies(df[var], prefix=var, drop_first=True)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df.drop(var, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "patients_df = one_hot_encode(patients_df, categorical_variables)\n",
    "control_df = one_hot_encode(control_df, categorical_variables)\n",
    "\n",
    "\n",
    "# 标准化连续变量\n",
    "scaler = StandardScaler()\n",
    "control_df[continuous_variables] = scaler.fit_transform(control_df[continuous_variables])\n",
    "patients_df[continuous_variables] = scaler.transform(patients_df[continuous_variables])\n",
    "\n",
    "# 从对照组DataFrame中提取行为变量数据\n",
    "control_data = control_df[behavior_variables]\n",
    "\n",
    "# 使用对照组数据拟合StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(control_data)\n",
    "\n",
    "# 使用对照组的标准化参数标准化患者组数据\n",
    "standardized_patient_data = scaler.transform(patients_df[behavior_variables])\n",
    "standardized_patient_df = pd.DataFrame(standardized_patient_data, columns=behavior_variables)\n",
    "\n",
    "# 从数据框中获取所有人口学变量（已独热编码和标准化）\n",
    "demographic_variables = [col for col in control_df.columns if col not in behavior_variables]\n",
    "\n",
    "# 使用对照组数据拟合回归模型校正人口学效应\n",
    "corrected_patient_data = pd.DataFrame()\n",
    "\n",
    "for variable in behavior_variables:\n",
    "    model = LinearRegression()\n",
    "    model.fit(control_df[demographic_variables], control_df[variable])\n",
    "    correction = model.predict(patients_df[demographic_variables])\n",
    "    corrected_values = standardized_patient_df[variable] - correction\n",
    "    corrected_patient_data[variable] = corrected_values\n",
    "\n",
    "# 将校正后并标准化后的数据保存为新的Excel文件\n",
    "corrected_patient_df = pd.DataFrame(corrected_patient_data)\n",
    "corrected_patient_df.to_excel('./table/校正并标准化后的患者行为变量数据.xlsx', index=False)\n",
    "\n",
    "# 打印校正并标准化后的DataFrame\n",
    "print(corrected_patient_df.head())\n",
    "\n",
    "print(\"校正并标准化完成，数据已保存到'./table/校正并标准化后的患者行为变量数据.xlsx'.\")\n",
    "\n",
    "# 计算校正并标准化后的均值和标准差\n",
    "corrected_patient_means = corrected_patient_df.mean().round(2)\n",
    "corrected_patient_stds = corrected_patient_df.std().round(2)\n",
    "\n",
    "# 创建一个DataFrame来存储结果，以“均值±标准差”格式显示\n",
    "summary_df = pd.DataFrame({\n",
    "    'Corrected and Standardized Patient': corrected_patient_means.astype(str) + ' ± ' + corrected_patient_stds.astype(str)\n",
    "}, index=behavior_variables)\n",
    "\n",
    "# 打印结果\n",
    "print(summary_df)\n",
    "\n",
    "# 保存结果为Excel文件\n",
    "summary_df.to_excel('./table/校正并标准化后的患者行为变量均值和标准差.xlsx')\n",
    "\n",
    "print(\"校正并标准化后的均值和标准差已保存到'./table/校正并标准化后的行为变量均值和标准差.xlsx'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据分析全部完整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据分析全部完成！\n"
     ]
    }
   ],
   "source": [
    "print('数据分析全部完成！')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
